---
title: "BellaBeat Case Of Study - For GoogleÂ´s Data Analyst Career Path V2.0"
author: "Miguel Di Lalla"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: flatly
    code_folding: hide
    includes:
      after_body: footer.html
---

<!-- # ```{r setup, include=FALSE} -->
<!-- # knitr::opts_chunk$set(echo = T) -->
<!-- # ``` -->

# ____________________________________________________
<style>
div.blue { background-color:#bdffd9; border-radius: 14px; padding: 20px;}
</style>
<div class = "blue">

# [ACT] Key High-Level Insights from this Study: 

### - The data suggested for the study is poor in size, consistency and demographics. Similar data for a study of this kind is sealed behind paywalls. 

(Movement and vital stats recorded with commercial monitoring devices.)

### - The few identifiable trends were that around half the time, users don't sleep track. Also in half of the records people in this study presented healthy physical activity patterns.

(Still, vague facts that can not be related to gender, age, device characteristics or anything else.)

### - The heterogeneous behavioral patterns of this small population point to an equaly heterogenous composition  for the whole market target.

(Would have been truly useful to have had first-hand access to Bellabeat customers' data where relevant trends are to be discovered for sure.)

#### - *Note that this Case of Study's purpose is to showcase the dexterity using R Studio and R language as main tool for Junior Data Analyst Tasks*

</div>
# ____________________________________________________

# [ASK] Objectives of this Study:

Bellabeat is a high-tech company that manufactures health-focused smart products and beautifully developed and designed technology that informs and inspires women around the world. Collecting data on activity, sleep, stress, and reproductive health has allowed Bellabeat to empower women with knowledge about their own health and habits.

***

###This study's objectives

#### To find out about trends in smart device usage

##### Then

#### How could these trends apply to Bellabeat customers? 

#### How could these trends help influence Bellabeat's marketing strategy? 

***

# [PREPARE] The data on which this work will be sustained

For this case of study we have been given the following public [dataset](https://zenodo.org/records/53894#.YMoUpnVKiP9) published originally by a team from the RTI International Organization and then shared in the Kaggle platform by the prominent community Member "[Mobius](https://www.kaggle.com/arashnic)". Taking advantage of the public domain status.

These datasets were generated by respondents to a distributed survey via Amazon Mechanical Turk between 03.12.2016 and 05.12.2016.  Thirty eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring.

***

It is worth it to name the factors that would determine the reliability of this data:

- This dataset originated via a survey using the outsourcing private platform "Amazon Mechanical Turk" It is not first-hand data.

- The "Research Triangle Institute International" is a non-profit Organization founded in 1958. Integrated by three prominent USA Universities. It is the main affiliation from the group that forged the dataset.

- The Kaggle member who has shared this in the Kaggle platform showcases an exceptional professional profile from a collaborative member and humanities-oriented worker. 

***

For this study, the RStudio Desktop tool has been used. 18 ".cvs" files have been downloaded into the project directory and loaded into the working environment for a first glance. Two main tables summarize on a daily scale what is stored with 5 min resolution in separated entities for each metric (Calories consumption, Sleeping state, Steps taken and Activity intensities based on Heart Rate) in both wide and narrow format. There are a few obvious errors in formatting for some columns due to the importation process, they are addressed further during the Data Validation in the Process phase of this document.

This is a dataset representing a little sample of the kind of population that uses fitness tracking devices. It is not specific though, since the mean target of our stakeholder are women, but for a demonstration of habilites, it will do.

***

# [PROCESS] Cleansing and Manipulation.


#### Let's start by loading the tables and libraries that are to be used in the project:

```{r message=FALSE, warning=FALSE}
options(repos = "https://cran.r-project.org")
install.packages("tidyverse")
install.packages("gt")
install.packages('treemapify')
install.packages('plotly')
install.packages('DT')
library(tidyverse)
library(gt)
library(treemapify)
library(plotly)
library(DT)
```
The libraries used for the project were the typical "Tidyverse" for all the data manipulation and four other more to enhance the quality of the Viz and tables in the document: GT, Treemapify, Plotly and DT.

#### Giving easy-to-access-names to each one of the 18 original tables from the dataset:

```{r message=FALSE, warning=FALSE}
DailyAct <-read.csv("dailyActivity_merged.csv")
DailyCal <-read.csv("dailyCalories_merged.csv")
DailyInt <-read.csv("dailyIntensities_merged.csv")
DailySte <-read.csv("dailySteps_merged.csv")
DailySle <-read.csv("sleepDay_merged.csv")
SecHR <-read.csv("heartrate_seconds_merged.csv")
HourCal <-read.csv("hourlyCalories_merged.csv")
HourInt <-read.csv("hourlyIntensities_merged.csv")
HourSte <-read.csv("hourlySteps_merged.csv")
MinCalN <-read.csv("minuteCaloriesNarrow_merged.csv")
MinCalW <-read.csv("minuteCaloriesWide_merged.csv")
MinIntN <-read.csv("minuteIntensitiesNarrow_merged.csv")
MinIntW <-read.csv("minuteIntensitiesWide_merged.csv")
MinMETn <-read.csv("minuteMETsNarrow_merged.csv")
MinSle <-read.csv("minuteSleep_merged.csv")
MinSteN <-read.csv("minuteStepsNarrow_merged.csv")
MinSteW <-read.csv("minuteStepsWide_merged.csv")
WeiLog <-read.csv("weightLogInfo_merged.csv")
```

A member of the kaggle community shared in the dataset forum an [oficial FitBit dictionary](https://www.fitabase.com/media/1930/fitabasedatadictionary102320.pdf) from FitBit to their logs. Examining the tables using RStudio a pipeline has been traced

This work's focus is in the daily outcome from the participants, knowing that the minutely and hourly tables can be used for checking consistency, they will be omitted for the purpose of this work.

All the daily records will be collapsed into a "MainTable" on which the further analysis is going to take place.

***

#### Taking a glimpse from the tables where all the data to use will come from:

```{r}
glimpse(DailyAct)
glimpse(DailySle)
glimpse(WeiLog)
```

#### The "Id" Columns are stored as "dbl" and the dates as "chr", that has to be fixed. First by creating "working copies" so the original data can be accessed at any moment.

```{r}
DailyAct2 <- DailyAct
DailySle2 <- DailySle
WeiLog2 <- WeiLog
```

#### Then the column's variable type are corrected:

```{r}
# first the dates 
DailyAct2$ActivityDate <- mdy(DailyAct2$ActivityDate)
DailySle2$SleepDay <- mdy_hms(DailySle2$SleepDay)
DailySle2$SleepDay <- date(DailySle2$SleepDay)
DailySte$ActivityDay <- mdy(DailySte$ActivityDay)
WeiLog2$Date <- mdy_hms(WeiLog2$Date)
WeiLog2$Date <- date(WeiLog2$Date)
# Then the Ids
DailyAct2$Id <- as.character(DailyAct2$Id)
DailySle2$Id <- as.character(DailySle2$Id)
WeiLog2$Id <- as.character(WeiLog2$Id)
#lastly the boolean column that appears with char type
WeiLog2$IsManualReport <- as.logical(WeiLog2$IsManualReport)
```

#### At this stage the tables doenst have a primary key that could evntually bound them. It can be created by concatenating the Id and Date columns:

```{r}
DailyAct2 <- DailyAct2 %>% unite(col="key",c(Id,ActivityDate),sep = " ",remove = FALSE)
DailySle2 <- DailySle2 %>% unite(col="key",c(Id,SleepDay),sep = " ",remove = FALSE)
WeiLog2 <- WeiLog2 %>%  unite(col="key", c(Id,Date),sep = " ",remove = FALSE)
```

#### Now lets check for duplicates:

There are 940 rows, should be the same number of different keys

```{r}
DailyAct2 %>% distinct(key) %>% count()
```
CORRECT

413 rows in the sleep table.
```{r}
DailySle2 %>% distinct(key) %>% count()
```
Only 410 different keys. Lets get rid of the duplicates by simply:

```{r}
DailySle2 <- unique(DailySle2)
```

67 rows for the last one.
```{r}
WeiLog2 %>% distinct(key) %>% count()
```
All correct now.

#### Joining the three tables together:

```{r}
MainTable <- full_join(DailyAct2,DailySle2, by = c("key" = "key", "Id" = "Id", "ActivityDate" = "SleepDay"))
MainTable <- full_join(MainTable, WeiLog2, by = c("key" = "key","Id" = "Id", "ActivityDate" = "Date"))
```

#### Taking a glimpse to what have done:

```{r}
datatable(MainTable, rownames = FALSE, options = list(pageLength = 10, scrollX=T))
#gt(sample_n(MainTable,15))
MainTable %>% glimpse()
MainTable %>% summary()
```

#### This "primordial" working table that contains all the information that was not discarded has to be cleaned and checked. for that every one of the 25 columns will be examined for inconsistencies:

- The key, ID and Date look nice since they were cast previously, it can be confirmed that the dates go from April 12 to May 12. 

- TotalSteps seem to follow a normal pattern with a median of 7439 and a maximum of 36000 steps (knowing the trend of 10000 steps per day). 

- There are seven distance columns measured in kilometres (see the linked [dictionary](https://www.fitabase.com/media/1930/fitabasedatadictionary102320.pdf)) on which no user logged more than 30 km. 

- The following four columns got total minutes counters of different levels of physical activity. Since a day only got 1440 minutes, no max value should exceed that, which is satisfied. 

- The average human adult should spend around 2400 Kcal per day, which corresponds to the Mean value of the column. 

- The recommended sleeping hours are 8 for the average individual, that is 480 minutes, validating the values from the three columns of sleeping records. 

- Finally, there are weight records from very few users and their values are also consistent with common human parameters.

***

#### For a second scanning of the data it is useful to execute some queries and operations:

Since the data consist of 30 people record from April 12 to May 12 (31 days), there should be 930 observations, but there are 943. And duplicates has already been erased, Lets count how many user Ids there are:

```{r}
MainTable %>% distinct(Id) %>% count()
```

There are 33 IDs, that can be explained by a paragraph in the dataset repository where the author noted that some users got more than one device. And there is no way to identify them. With 33 users there should be 1023 observations, which is not the case.

***

#### The number of days tracked on every user could be useful later:
```{r}
MainTable$Id <- as.factor(MainTable$Id) 
# the "factor" data type can be useful in this scenario
IdCount<- as.data.frame(fct_count(MainTable$Id)) 
# a table that counts the number of dates associated with every Id
colnames(IdCount) <- c('Ids', 'DaysRec') 
# Renaming the columns
IdCount
```

Thereby the reason there are no 1023 rows. Many users have less that 31 days recorded.

***

# [ANALYSE] Framing the data into meaning

#### Creating cathegorical data columns to enhance further visualizations.

Beginning with the step count. The Centers for Disease Control and Prevention (CDC) recommends a range between 6000 and 7000 to begin feeling the benefices from the activity, with an optimal number of 10000, and nothing below 4000 steps. This way we can come out with five different rankings

```{r}
MainTable$SteQu <- MainTable$TotalSteps %>% cut(breaks = c(-1, 4000, 5499, 7499, 10000, 40000), labels = c('too little', 'good', 'optimal', 'great', 'amazing'))
# "SteQu" = Quality of the Steps count
# then the table function counts all the occurrences
table(MainTable$SteQu)
```
***

It is also useful to know which participants got at least 30 days of records. For that the previously created IdCount table is merged with our Main table and then those numbers can be "classified":

```{r}
MainTable <- full_join(MainTable, IdCount, by = c('Id' = 'Ids'))
MainTable$DaysRec <- MainTable$DaysRec %>% cut(breaks = c(0, 30,32), labels = c('Less', 'Up to 30'))
table(MainTable$DaysRec)
```

There are up to 24 users in this data that got 30 to 31 days recorded.

***

Another detail is to assign a simpler number to each of the users. Otherwise the Id would be represented in an uncomfortable scale in the visualizations.

```{r}
MainTable <- full_join(MainTable, data.frame(MainTable %>% select(Id) %>% distinct(), n = c(1:33)), by = "Id")
unique(MainTable %>% reframe(Id, n))
```
***

Same previous process with the column on distances manually logged:

```{r}
MainTable$ManuallyLogDist <- MainTable$LoggedActivitiesDistance %>% cut(breaks = c(-5, 0, 5), labels = c('Did not', 'Did'))
table(MainTable$ManuallyLogDist)
MainTable %>% filter(ManuallyLogDist == 'Did') %>% distinct(Id) %>% count()
```
Only 33 observations got manually logged distance, and they come from only 4 different users.

***

Since not all users recorded during the full time for the survey, they probably didnt wear their devices 24 hours either. Activity counters and sleeping counters should add 1440 minutes together each day:

```{r}
# filling the NAs from the sleepy columns
MainTable$TotalMinutesAsleep <- MainTable$TotalMinutesAsleep %>% replace_na(0)
MainTable$TotalTimeInBed <- MainTable$TotalTimeInBed %>% replace_na(0)

#There are two different sleep counters, time in bed and time asleep
summary(
  MainTable %>% 
    filter(!is.na(TotalSleepRecords)) %>% 
    reframe(key, 
            ActivityMinutes = (VeryActiveMinutes + FairlyActiveMinutes + LightlyActiveMinutes + SedentaryMinutes),
            TotalMinutesAsleep, 
            TotalLog1 = ( ActivityMinutes + TotalMinutesAsleep),
            TotalTimeInBed, 
            TotalLog2 = ( ActivityMinutes + TotalTimeInBed)
            )
  )
```

In both cases the sums add up to 1440 as median value tho in both can reported higher values making these columns relate to each other inconsistently. So a "Total Minutes Log" counter can only be defined as aproximate value:

```{r}
MainTable <- full_join(MainTable,(MainTable %>%
    reframe(key,
            AwakenMin = (VeryActiveMinutes + FairlyActiveMinutes + LightlyActiveMinutes + SedentaryMinutes),

            TotalLogAprox = ( AwakenMin + TotalTimeInBed) #using TotalTimeInBed witch presented the lesser variation
            )
    ), by = c("key" = "key")
)
summary(MainTable$TotalLogAprox)
# the addition to a NULL value created NAs, they can be filled with the AwakenMin values:
MainTable <- mutate(MainTable, TotalLogAprox = coalesce(TotalLogAprox, ifelse(is.na(TotalLogAprox), AwakenMin, NA)))
summary(MainTable$TotalLogAprox)
#done.
# Adding a column that says if that day the user got a 24 hours record
MainTable$FullDayRec <- MainTable$TotalLogAprox %>% cut(breaks = c(-1, 1439, 2000), labels = c('No', 'YES'))
summary(MainTable$FullDayRec)
# 755 observations are 24 observations, 81%
```
***

The CDC also recommends 30 minutes of moderate intensity activity per day, half of it if it is intense. Using this information the following rank is added:

```{r}
MainTable <- full_join(MainTable,(MainTable %>%
    reframe(key,
            ExerQu = (VeryActiveMinutes*2 + FairlyActiveMinutes ) #+ LightlyActiveMinutes/2
            )
    ), by = c("key" = "key")
)
# Turning it into factors
MainTable$ExerQu <- MainTable$ExerQu %>% cut(breaks = c(-1, 29, 60, 600), labels = c('defficient', 'Great', 'Amazing'))
table(MainTable$ExerQu)
```

A visualization about who and when got their sleep night recorded will be useful. A column of boolean data based on the column with the number of sleep records per day is a good option:

```{r}
# filling the Null with zeroes
MainTable$TotalSleepRecords <- MainTable$TotalSleepRecords %>% replace_na(0)
MainTable$SleRec <- MainTable$TotalSleepRecords %>% cut(breaks = c(-1, 0.9, 4), labels = c('Aint', 'Has'))
summary(MainTable$SleRec)
# Notice that the cut() function must be treated carefully for the breaks to apply properly.
```
410 sleep records as the number of rows in the original sleep table.

***

From the sleep minutes counters can be extracted the hours, on which the CDC got recommend values around 8 hours.

```{r}
MainTable <- full_join(MainTable,(MainTable %>%
    reframe(key,
            SleHours = (TotalMinutesAsleep/60)
            )
    ), by = c("key" = "key")
)
# Turning the sleep hours into categories
MainTable$SleHours <- MainTable$SleHours %>% cut(breaks = c(-1, 6.9, 9, 15), labels = c('Deficit', 'Good', 'TooMuch'))
summary(MainTable$SleHours)
```
To that "deficit" count has to be subtracted the numbers of days without sleep recordings (530), leaving the count in 173.

***

Turn for the Weight Log data, which is quite scarse as it follows:
```{r}
MainTable %>% filter(!is.na(WeightKg)) %>% distinct(Id) %>% count()
# only 8 participants got tha information logged
summary(MainTable$WeightKg)
# in only 67 observations.
# these columns are more useful translated into whether the users logged the information, how and when:
# It all can be done transforming the "IsManualReport" column because it has
# already the 3 possible values of interest
MainTable$IsManualReport <- as.numeric(MainTable$IsManualReport)
MainTable$IsManualReport <- replace_na(MainTable$IsManualReport, 2)
MainTable$IsManualReport <- MainTable$IsManualReport %>% cut(breaks = c(-1,0, 1,2), labels = c('NonManual', 'Manual', 'Empty'))
summary(MainTable$IsManualReport)
```
***

#### Checking main variables looking for outstanding data point:

(This should have been done during the Processing Phase but the new categorical columns created for the analysis are useful to identify some patterns to beware before making any conclusion.)

Starting with the Steps counter

```{r}
ggplotly(MainTable %>% ggplot() + geom_point(mapping = aes(x = ActivityDate, y = TotalSteps, fill = Id))+ theme(legend.position="none"))
```
Quite an even cloud but its weird to have so many point close to zero. The following count represent the amount of observation under 3000, 300 and 30 in that order:

```{r}
MainTable %>% filter(TotalSteps <= 3000) %>% count()
MainTable %>% filter(TotalSteps <= 300) %>% count()
MainTable %>% filter(TotalSteps <= 30) %>% count()
```

Almost 20% of the rows exhibit records under 3000 steps, half of those are under 300 and 79 observations under 30 steps for different people on different days. Weird but not isolated cases.

***

Continuing with the SedentaryActivity minutes counter

```{r}
ggplotly(MainTable %>% ggplot() + geom_point(mapping = aes(x = ActivityDate, y = SedentaryMinutes, fill = Id))+ theme(legend.position="none"))
MainTable$SedentaryMinutes %>% summary()
# Mean value of 989.3
```

There seem to be two "groups" on the last scatter plot. This variable got a max in 1440 (The number of minutes in a day) but it should not include the time asleep, that is a different counter. The average sleep night got 480 minutes, that leaves 960 Minutes for the awaken time (corresponding with the Mean value of the variable).

What if the points are filtered with the condition of having sleepLog:

```{r}
# First the days with SlepLog, then the days without
ggplotly(MainTable %>% filter(SleRec == 'Has') %>% ggplot() + geom_point(mapping = aes(x = ActivityDate, y = SedentaryMinutes, fill = Id))+ theme(legend.position="none"))

ggplotly(MainTable %>% filter(SleRec == 'Aint') %>% ggplot() + geom_point(mapping = aes(x = ActivityDate, y = SedentaryMinutes, fill = Id))+ theme(legend.position="none"))

# The days with SlepLog
(MainTable %>% filter(SleRec == 'Has'))$SedentaryMinutes %>% summary()
# The days without
(MainTable %>% filter(SleRec == 'Aint'))$SedentaryMinutes %>% summary()
```
The answer to this phenomenon is already in the completeness of the original files, where the the "DailySleep" table had less than half of the observations that the "DailyActivity" had. Still none of this groups are to be disposed of. Again weird, so many days with so little time remaining for sleeping. But that can be due to devices failures.

```{r echo=TRUE}
table(as.factor(DailySle2$TotalSleepRecords))
# Tho its weird, again, that most days have only one sleep records, that, 
# or most of the people in this survey went to bed after midnight. 
# Otherwise there should be at least two records per day.

MainTable %>% filter(SedentaryMinutes >= 1300) %>% count()
# Obs above 1300 min
MainTable %>% filter(SedentaryMinutes <= 400) %>% count()
# Obs under 400 Min
```
***

Now, about the Calories:

```{r}
ggplotly(MainTable %>% ggplot() + geom_point(mapping = aes(x = ActivityDate, y = Calories, fill = Id))+ theme(legend.position="none"))
MainTable$Calories %>% summary()
MainTable %>% filter(Calories <= 1000) %>% count()
```

A Mean value of 2313 Kcal, which corresponds to the average adult daily consumption 2400. But there are 12 observations that fall out the scatter cloud.

If the rows with those values are examined:

```{r}
datatable((MainTable %>% filter(Calories <= 1000) %>% reframe(n, ActivityDate, Calories, TotalSteps, TotalLogAprox,  AwakenMin, TotalTimeInBed, SedentaryMinutes, FullDayRec)), rownames = FALSE, options = list(pageLength = 25, scrollX=T))
```

Eight of them turn out to be days on which the users (all of them different) only wore the device while sleeping or during a very short period of time. While 4 rows are actually null observations that can be disposed of:

```{r}
MainTable <- MainTable %>% filter(Calories != 0)
```

***

## Exploratory Vizualizations

### How complete is the data?

It is true that previous calculations would have already shown counts that tells how complete the data is. But this "Tiles Graphs" are a great way to showcase users behavior on each variable in the way a timeline does.
Empty spaces represent days where there is not data recorded at all.
Kepping in mind that the data doesn't provide with demographics to draw correlations, still some observations can be made about this small population:

```{r out.width=c('50%', '50%', '50%'), fig.show='hold'}
ggplot(MainTable) + geom_tile(mapping = aes(x = ActivityDate, y = n, fill = DaysRec)) 
ggplot(MainTable) + geom_tile(mapping = aes(x = ActivityDate, y = n, fill = TotalLogAprox)) 
ggplot(MainTable) + geom_tile(mapping = aes(x = ActivityDate, y = n, fill = FullDayRec), color = "white")
```

In the graphics above first Viz highlight in Cyan the users who got records every day that the original survey contemplated. The Viz to the right shows how many minutes they got recorded each day and last one direcly highlight who got 24 hours and who did not.

### The ones who SleepTrack

```{r out.width=c('50%', '50%'), fig.show='hold'}
ggplot(MainTable) + geom_tile(mapping = aes(x = ActivityDate, y = n, fill = SleRec), color = "white")
ggplot(MainTable %>% filter(SleRec == 'Has')) + geom_tile(mapping = aes(x = ActivityDate, y = n, fill = SleHours)) + scale_fill_brewer(palette="BuPu") + theme_dark()
gt(fct_count((MainTable %>% filter(SleRec == 'Has'))$SleHours))
(173/410)*100
MainTable$SleRec %>% fct_count()
(410/936)*100

MainTable %>% filter(SleRec == 'Has',SleHours == 'Defficit') %>% distinct(Id) %>% count()

MainTable %>% filter(SleRec=='Aint',FullDayRec=='YES') %>% count()

```
From this population, Just three subjects sleep-tracked during the full study, the rest of them got blacks here and there. Eight users never Sleep Tracked and the numbers goes up to 17 if the ones who did rarely are counted (Those with very few entrances). That is half the sample and the same pattern can be observed in the number of sleeping period counted. From 936 observations in the main table, only 44% got sleep data, from that data up to 42% of the tracked periods categorized as sleep deficit.

```{r}
ggplot(MainTable) + geom_tile(mapping = aes(x = ActivityDate, y = n, fill = SteQu)) + scale_fill_brewer(palette="Accent") + theme_minimal()
MainTable$SteQ %>% summary
(243/936)*100
```
Most of the data we got available can only be used to set average values of behavior. For example the Step-Counting shows that on 74% of the observations the minimum of recommended walking was met. And most of the log below that minimum corresponds to the same 6 users (20% of the sample.)

```{r}
ggplot(MainTable) + geom_tile(mapping = aes(x = ActivityDate, y = n, fill = ManuallyLogDist))
```
With only this plot can be said that the idea of manually logging data is nos popular for this sample of people. Only two of them really tried and did with deficient consistence.

```{r}
ggplot(MainTable) + geom_tile(mapping = aes(x = ActivityDate, y = n, fill = ExerQu)) + scale_fill_brewer(palette="Set1")
```
This last Viz shows a variety of patterns due to physical activity. Half of the records are deficient, nevertheless the ones that go beyond the CDC recommendations are majority inside the ones who meet the minimum. The behaviors are really mixed from person to person.

***

# SHARE The Key Findings

```{r out.width=c('50%', '50%', '50%'), fig.show='hold'}
ggplot((as.data.frame(table(MainTable$SteQu))), aes(area = Freq, fill = Var1, label = Var1)) + geom_treemap() + geom_treemap_text(colour = "black", place = "centre") + theme(legend.position="none") + labs(title = "Average Step Count Quality") + scale_fill_brewer(palette="Accent") 
ggplot((as.data.frame(table((MainTable %>% filter(SleRec == 'Has'))$SleHours))), aes(area = Freq, fill = Var1, label = Var1)) + geom_treemap() + geom_treemap() + geom_treemap_text(colour = "black", place = "centre") + theme(legend.position="none") + labs(title = "Average Sleep-Time Quality") + scale_fill_brewer(palette="BuPu")
ggplot((as.data.frame(table(MainTable$ExerQu))), aes(area = Freq, fill = Var1, label = Var1)) + geom_treemap() + geom_treemap() + geom_treemap_text(colour = "white", place = "centre", size = 15)+ scale_fill_brewer(palette="Set1") + theme(legend.position="none") + labs(title = "Average Intense-Activity-Minutes per day Quality")
```

- The Data available has a lot of deficiencies. Starting with a Sleep-Log from which it could be concluded that half of the times, people wear off their devices before going to bed. But in the observations without Sleep-Log most of them also report to be 24-hours records, implying that half of the time, people did not even sleep, which makes no sense. This could point to deficient sleep recording mechanism on the devices but for 2016 this was an already industry standard (Since 2010). It is true that not even acelerometers has achieve Medical Equipment accuracy.

- Step counting and physical activity rates show mixed behavioral patters that due to the small number of our sample and the lack of demographic information, no trend can be drawn.

***

# [ACT]
<style>
div.blue { background-color:#bdffd9; border-radius: 14px; padding: 20px;}
</style>
<div class = "blue">
## note:

The Key high-level insights has been summarized at the [top of the Document](#top).
</div>


<br><br><br><br>